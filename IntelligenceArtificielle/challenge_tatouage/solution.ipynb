{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch as t\n",
    "\n",
    "from challenge_gorfoustral.gorfougym import load_model_vague_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1801c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-instruct-33M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = load_model_vague_2(device=\"cuda\", dtype=t.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886350a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"challenge_tatouage/journal35.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f180a",
   "metadata": {},
   "source": [
    "## 1ère étape : Trouver les phrases tatouées\n",
    "\n",
    "Pour ça on peut utiliser la perplexité. C'est une mesure qui donne la probabilité que la phrase aie été générée par le modèle. Si la phrase est tatouée, la perplexité augmente car les jetons choisis ne sont plus forcément dans les premiers choix. \n",
    "\n",
    "Pour GPT2 et la méthode de tatouage proposée, la perplexité permet de distinguer la majorité des cas : \n",
    "\n",
    "![ppls](../assets/ppls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3ef95",
   "metadata": {},
   "source": [
    "Pour faciliter le challenge, j'ai selectionné les phrases de telle sorte que toutes les perplexitées des phrases tatouées soient plus élevées que toutes les perplexitées des phrases non tatouées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5f7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppls = []\n",
    "\n",
    "for x in data:\n",
    "    tokens = model.to_tokens(x)\n",
    "    loss = model.forward(tokens, return_type=\"loss\")\n",
    "    ppls.append((loss.item(), x))\n",
    "\n",
    "\n",
    "ppls_ranked = sorted(ppls, key=lambda x: x[0], reverse=True)\n",
    "watermarked_sentences = [x[1] for x in ppls_ranked[: len(ppls_ranked) // 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347291e",
   "metadata": {},
   "source": [
    "## 2ème étape : Trouver des suites de jetons récurrentes\n",
    "\n",
    "L'idée est très simple, si l'on a plusieurs fois la suite a-b-x avec plusieurs x différents, alors on peut essayer de reconstruire le masque utilisé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ab803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "start_idx = 20\n",
    "mask_len = 10\n",
    "\n",
    "for prompt in watermarked_sentences:\n",
    "    tokens = model.to_tokens(prompt)[0]\n",
    "    for i in range(start_idx, len(tokens) - 2):\n",
    "        d[tokens[i].item(), tokens[i + 1].item()] = d.get(\n",
    "            (tokens[i].item(), tokens[i + 1].item()), set()\n",
    "        ).union(set([tokens[i + 2].item()]))\n",
    "\n",
    "# Filtre sur les paires qui apparaissent au moins mask_len fois, sinon aucune chance\n",
    "# d'avoir le masque en entier\n",
    "dd = {}\n",
    "for k, v in d.items():\n",
    "    if len(v) > mask_len:\n",
    "        dd[k] = v\n",
    "\n",
    "jetons_récurrents = [(k[0], k[1], list(v), len(v)) for k, v in dd.items()]\n",
    "jetons_récurrents = sorted(jetons_récurrents, key=lambda x: x[-1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ecaf1",
   "metadata": {},
   "source": [
    "## 3ème étape : Reconstruction du masque\n",
    "\n",
    "Une fois les jetons récurrents trouvés, il faut extraire le début des phrases, tout ce qui est entre 20 (début du tatouage) et la séquence a-b-x, pour pouvoir reformer le masque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "potentiels_masques = []\n",
    "\n",
    "for r in jetons_récurrents:\n",
    "    tok1, tok2, _, _ = r\n",
    "    masque = []\n",
    "    generations = []\n",
    "\n",
    "    for x in watermarked_sentences:\n",
    "        tokens = model.to_tokens(x)[0]\n",
    "        parts = []\n",
    "        for i in range(start_idx, len(tokens) - 2):\n",
    "            if tokens[i] == tok1 and tokens[i + 1] == tok2:\n",
    "                parts.append(tokens[: i + 3])\n",
    "\n",
    "        if len(parts) > 0:\n",
    "            generations.append(parts)\n",
    "\n",
    "    for x in generations:\n",
    "        for y in x:\n",
    "            tokens, next_tok = y[:-1], y[-1]\n",
    "            logits = model(tokens)\n",
    "            _, indices = logits[0, -1, :].topk(k=2 * mask_len)\n",
    "\n",
    "            try:\n",
    "                finder = (indices == next_tok).nonzero()\n",
    "                masque.append(finder[0][0].item())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if len(set(masque)) == mask_len:\n",
    "        potentiels_masques.append((masque, *r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4876635",
   "metadata": {},
   "source": [
    "## 4ème étape : Récupération de la seed\n",
    "\n",
    "Une fois le masque récupéré, il suffit d'énumérer le \"cryptage très puissant\" pour récupérer la seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef96619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43633]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from challenge_tatouage.tatouage import get_mask\n",
    "\n",
    "\n",
    "def get_seed_from_mask(mask_orig, mask_len: int):\n",
    "    results = []\n",
    "    for i in range(99999):\n",
    "        if t.equal(mask_orig, get_mask(i, mask_len=mask_len)):\n",
    "            results.append(i)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = []\n",
    "for potentiel_masque in potentiels_masques:\n",
    "    generation, tok1, tok2, _, _ = potentiel_masque\n",
    "\n",
    "    mask = t.zeros(mask_len * 2, dtype=t.bool)\n",
    "    mask[list(set(generation))] = True\n",
    "    seeds = get_seed_from_mask(mask, mask_len=mask_len)\n",
    "\n",
    "    for seed in seeds:\n",
    "        for i in range(50033):\n",
    "            if (tok2 * i + tok1) % 50033 == seed:\n",
    "                results.append(i)\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vents2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
